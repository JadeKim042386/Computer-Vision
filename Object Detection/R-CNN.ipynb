{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "설명 : https://herbwood.tistory.com/5  \r\n",
    "코드 : https://github.com/object-detection-algorithm/R-CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\r\n",
    "import cv2\r\n",
    "import os\r\n",
    "import copy\r\n",
    "import time\r\n",
    "import random\r\n",
    "\r\n",
    "import numpy as n\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torchvision.models as models\r\n",
    "from torchvision.models import alexnet\r\n",
    "\r\n",
    "from utils.data.custom_finetune_dataset import CustomFinetuneDataset\r\n",
    "from utils.data.custom_batch_sampler import CustomBatchSampler\r\n",
    "from utils.data.custom_classifier_dataset import CustomClassifierDataset\r\n",
    "from utils.data.custom_hard_negative_mining_dataset import CustomHardNegativeMiningDataset\r\n",
    "from utils.data.custom_bbox_regression_dataset import BBoxRegressionDataset\r\n",
    "\r\n",
    "from utils.util import check_dir\r\n",
    "from utils.util import save_model\r\n",
    "import utils.util as util\r\n",
    "\r\n",
    "import selectivesearch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selective Search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_selective_search():\r\n",
    "    gs = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\r\n",
    "    return gs\r\n",
    "\r\n",
    "def config(gs, img, strategy='q'):\r\n",
    "    gs.setBaseImage(img)\r\n",
    "\r\n",
    "    if (strategy == 's'):\r\n",
    "        gs.switchToSingleStrategy()\r\n",
    "    elif (strategy == 'f'):\r\n",
    "        gs.switchToSelectiveSearchFast()\r\n",
    "    elif (strategy == 'q'):\r\n",
    "        gs.switchToSelectiveSearchQuality()\r\n",
    "    else:\r\n",
    "        print(__doc__)\r\n",
    "        sys.exit(1)\r\n",
    "\r\n",
    "def get_rects(gs):\r\n",
    "    rects = gs.process()\r\n",
    "    rects[:, 2] += rects[:, 0]\r\n",
    "    rects[:, 3] += rects[:, 1]\r\n",
    "\r\n",
    "    return rects\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    gs = get_selective_search()\r\n",
    "\r\n",
    "    img = cv2.imread('<file_path>', cv2.IMREAD_COLOR)\r\n",
    "    config(gs, img, strategy='q')\r\n",
    "\r\n",
    "    rects = get_rects(gs)\r\n",
    "    print(rects)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine Tune"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data(data_root_dir):\r\n",
    "    transform = transforms.Compose([\r\n",
    "        transforms.ToPILImage(),\r\n",
    "        transforms.Resize((227, 227)),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
    "    ])\r\n",
    "\r\n",
    "    data_loaders = {}\r\n",
    "    data_sizes = {}\r\n",
    "    for name in ['train', 'val']:\r\n",
    "        data_dir = os.path.join(data_root_dir, name)\r\n",
    "        data_set = CustomFinetuneDataset(data_dir, transform=transform)\r\n",
    "        data_sampler = CustomBatchSampler(data_set.get_positive_num(), data_set.get_negative_num(), 32, 96)\r\n",
    "        data_loader = DataLoader(data_set, batch_size=128, sampler=data_sampler, num_workers=8, drop_last=True)\r\n",
    "\r\n",
    "        data_loaders[name] = data_loader\r\n",
    "        data_sizes[name] = data_sampler.__len__()\r\n",
    "\r\n",
    "    return data_loaders, data_sizes\r\n",
    "\r\n",
    "\r\n",
    "def train_model(data_loaders, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):\r\n",
    "    since = time.time()\r\n",
    "\r\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "    best_acc = 0.0\r\n",
    "\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
    "        print('-' * 10)\r\n",
    "\r\n",
    "        # Each epoch has a training and validation phase\r\n",
    "        for phase in ['train', 'val']:\r\n",
    "            if phase == 'train':\r\n",
    "                model.train()  # Set model to training mode\r\n",
    "            else:\r\n",
    "                model.eval()  # Set model to evaluate mode\r\n",
    "\r\n",
    "            running_loss = 0.0\r\n",
    "            running_corrects = 0\r\n",
    "\r\n",
    "            # Iterate over data.\r\n",
    "            for inputs, labels in data_loaders[phase]:\r\n",
    "                inputs = inputs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "\r\n",
    "                # zero the parameter gradients\r\n",
    "                optimizer.zero_grad()\r\n",
    "\r\n",
    "                # forward\r\n",
    "                # track history if only in train\r\n",
    "                with torch.set_grad_enabled(phase == 'train'):\r\n",
    "                    outputs = model(inputs)\r\n",
    "                    _, preds = torch.max(outputs, 1)\r\n",
    "                    loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "                    # backward + optimize only if in training phase\r\n",
    "                    if phase == 'train':\r\n",
    "                        loss.backward()\r\n",
    "                        optimizer.step()\r\n",
    "\r\n",
    "                # statistics\r\n",
    "                running_loss += loss.item() * inputs.size(0)\r\n",
    "                running_corrects += torch.sum(preds == labels.data)\r\n",
    "            if phase == 'train':\r\n",
    "                lr_scheduler.step()\r\n",
    "\r\n",
    "            epoch_loss = running_loss / data_sizes[phase]\r\n",
    "            epoch_acc = running_corrects.double() / data_sizes[phase]\r\n",
    "\r\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
    "                phase, epoch_loss, epoch_acc))\r\n",
    "\r\n",
    "            # deep copy the model\r\n",
    "            if phase == 'val' and epoch_acc > best_acc:\r\n",
    "                best_acc = epoch_acc\r\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "\r\n",
    "    time_elapsed = time.time() - since\r\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
    "        time_elapsed // 60, time_elapsed % 60))\r\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
    "\r\n",
    "    # load best model weights\r\n",
    "    model.load_state_dict(best_model_weights)\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "    data_loaders, data_sizes = load_data('./data/finetune_car')\r\n",
    "\r\n",
    "    model = models.alexnet(pretrained=True)\r\n",
    "\r\n",
    "    num_features = model.classifier[6].in_features\r\n",
    "    model.classifier[6] = nn.Linear(num_features, 2)\r\n",
    "\r\n",
    "    model = model.to(device)\r\n",
    "\r\n",
    "    criterion = nn.CrossEntropyLoss()\r\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\r\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\r\n",
    "\r\n",
    "    best_model = train_model(data_loaders, model, criterion, optimizer, lr_scheduler, device=device, num_epochs=25)\r\n",
    "\r\n",
    "    check_dir('./models')\r\n",
    "    torch.save(best_model.state_dict(), 'models/alexnet_car.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_positive = 32\r\n",
    "batch_negative = 96\r\n",
    "batch_total = 128\r\n",
    "\r\n",
    "\r\n",
    "def load_data(data_root_dir):\r\n",
    "    transform = transforms.Compose([\r\n",
    "        transforms.ToPILImage(),\r\n",
    "        transforms.Resize((227, 227)),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
    "    ])\r\n",
    "\r\n",
    "    data_loaders = {}\r\n",
    "    data_sizes = {}\r\n",
    "    remain_negative_list = list()\r\n",
    "    for name in ['train', 'val']:\r\n",
    "        data_dir = os.path.join(data_root_dir, name)\r\n",
    "\r\n",
    "        data_set = CustomClassifierDataset(data_dir, transform=transform)\r\n",
    "        if name is 'train':\r\n",
    "           \r\n",
    "            positive_list = data_set.get_positives()\r\n",
    "            negative_list = data_set.get_negatives()\r\n",
    "\r\n",
    "            init_negative_idxs = random.sample(range(len(negative_list)), len(positive_list))\r\n",
    "            init_negative_list = [negative_list[idx] for idx in range(len(negative_list)) if idx in init_negative_idxs]\r\n",
    "            remain_negative_list = [negative_list[idx] for idx in range(len(negative_list))\r\n",
    "                                    if idx not in init_negative_idxs]\r\n",
    "\r\n",
    "            data_set.set_negative_list(init_negative_list)\r\n",
    "            data_loaders['remain'] = remain_negative_list\r\n",
    "\r\n",
    "        sampler = CustomBatchSampler(data_set.get_positive_num(), data_set.get_negative_num(),\r\n",
    "                                     batch_positive, batch_negative)\r\n",
    "\r\n",
    "        data_loader = DataLoader(data_set, batch_size=batch_total, sampler=sampler, num_workers=8, drop_last=True)\r\n",
    "        data_loaders[name] = data_loader\r\n",
    "        data_sizes[name] = len(sampler)\r\n",
    "    return data_loaders, data_sizes\r\n",
    "\r\n",
    "\r\n",
    "def hinge_loss(outputs, labels):\r\n",
    "\r\n",
    "    num_labels = len(labels)\r\n",
    "    corrects = outputs[range(num_labels), labels].unsqueeze(0).T\r\n",
    "\r\n",
    "    margin = 1.0\r\n",
    "    margins = outputs - corrects + margin\r\n",
    "    loss = torch.sum(torch.max(margins, 1)[0]) / len(labels)\r\n",
    "\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "def add_hard_negatives(hard_negative_list, negative_list, add_negative_list):\r\n",
    "    for item in hard_negative_list:\r\n",
    "        if len(add_negative_list) == 0:\r\n",
    "            negative_list.append(item)\r\n",
    "            add_negative_list.append(list(item['rect']))\r\n",
    "        if list(item['rect']) not in add_negative_list:\r\n",
    "            negative_list.append(item)\r\n",
    "            add_negative_list.append(list(item['rect']))\r\n",
    "\r\n",
    "\r\n",
    "def get_hard_negatives(preds, cache_dicts):\r\n",
    "    fp_mask = preds == 1\r\n",
    "    tn_mask = preds == 0\r\n",
    "\r\n",
    "    fp_rects = cache_dicts['rect'][fp_mask].numpy()\r\n",
    "    fp_image_ids = cache_dicts['image_id'][fp_mask].numpy()\r\n",
    "\r\n",
    "    tn_rects = cache_dicts['rect'][tn_mask].numpy()\r\n",
    "    tn_image_ids = cache_dicts['image_id'][tn_mask].numpy()\r\n",
    "\r\n",
    "    hard_negative_list = [{'rect': fp_rects[idx], 'image_id': fp_image_ids[idx]} for idx in range(len(fp_rects))]\r\n",
    "    easy_negatie_list = [{'rect': tn_rects[idx], 'image_id': tn_image_ids[idx]} for idx in range(len(tn_rects))]\r\n",
    "\r\n",
    "    return hard_negative_list, easy_negatie_list\r\n",
    "\r\n",
    "\r\n",
    "def train_model(data_loaders, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):\r\n",
    "    since = time.time()\r\n",
    "\r\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "    best_acc = 0.0\r\n",
    "\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "\r\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
    "        print('-' * 10)\r\n",
    "\r\n",
    "        # Each epoch has a training and validation phase\r\n",
    "        for phase in ['train', 'val']:\r\n",
    "            if phase == 'train':\r\n",
    "                model.train()  # Set model to training mode\r\n",
    "            else:\r\n",
    "                model.eval()  # Set model to evaluate mode\r\n",
    "\r\n",
    "            running_loss = 0.0\r\n",
    "            running_corrects = 0\r\n",
    "\r\n",
    "            data_set = data_loaders[phase].dataset\r\n",
    "            print('{} - positive_num: {} - negative_num: {} - data size: {}'.format(\r\n",
    "                phase, data_set.get_positive_num(), data_set.get_negative_num(), data_sizes[phase]))\r\n",
    "\r\n",
    "            # Iterate over data.\r\n",
    "            for inputs, labels, cache_dicts in data_loaders[phase]:\r\n",
    "                inputs = inputs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "\r\n",
    "                # zero the parameter gradients\r\n",
    "                optimizer.zero_grad()\r\n",
    "\r\n",
    "                # forward\r\n",
    "                # track history if only in train\r\n",
    "                with torch.set_grad_enabled(phase == 'train'):\r\n",
    "                    outputs = model(inputs)\r\n",
    "                    # print(outputs.shape)\r\n",
    "                    _, preds = torch.max(outputs, 1)\r\n",
    "                    loss = criterion(outputs, labels)\r\n",
    "\r\n",
    "                    # backward + optimize only if in training phase\r\n",
    "                    if phase == 'train':\r\n",
    "                        loss.backward()\r\n",
    "                        optimizer.step()\r\n",
    "\r\n",
    "                # statistics\r\n",
    "                running_loss += loss.item() * inputs.size(0)\r\n",
    "                running_corrects += torch.sum(preds == labels.data)\r\n",
    "            if phase == 'train':\r\n",
    "                lr_scheduler.step()\r\n",
    "\r\n",
    "            epoch_loss = running_loss / data_sizes[phase]\r\n",
    "            epoch_acc = running_corrects.double() / data_sizes[phase]\r\n",
    "\r\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
    "                phase, epoch_loss, epoch_acc))\r\n",
    "\r\n",
    "            # deep copy the model\r\n",
    "            if phase == 'val' and epoch_acc > best_acc:\r\n",
    "                best_acc = epoch_acc\r\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\r\n",
    "\r\n",
    "        train_dataset = data_loaders['train'].dataset\r\n",
    "        remain_negative_list = data_loaders['remain']\r\n",
    "        jpeg_images = train_dataset.get_jpeg_images()\r\n",
    "        transform = train_dataset.get_transform()\r\n",
    "\r\n",
    "        with torch.set_grad_enabled(False):\r\n",
    "            remain_dataset = CustomHardNegativeMiningDataset(remain_negative_list, jpeg_images, transform=transform)\r\n",
    "            remain_data_loader = DataLoader(remain_dataset, batch_size=batch_total, num_workers=8, drop_last=True)\r\n",
    "\r\n",
    "            negative_list = train_dataset.get_negatives()\r\n",
    "\r\n",
    "            add_negative_list = data_loaders.get('add_negative', [])\r\n",
    "\r\n",
    "            running_corrects = 0\r\n",
    "            # Iterate over data.\r\n",
    "            for inputs, labels, cache_dicts in remain_data_loader:\r\n",
    "                inputs = inputs.to(device)\r\n",
    "                labels = labels.to(device)\r\n",
    "\r\n",
    "                # zero the parameter gradients\r\n",
    "                optimizer.zero_grad()\r\n",
    "\r\n",
    "                outputs = model(inputs)\r\n",
    "                # print(outputs.shape)\r\n",
    "                _, preds = torch.max(outputs, 1)\r\n",
    "\r\n",
    "                running_corrects += torch.sum(preds == labels.data)\r\n",
    "\r\n",
    "                hard_negative_list, easy_neagtive_list = get_hard_negatives(preds.cpu().numpy(), cache_dicts)\r\n",
    "                add_hard_negatives(hard_negative_list, negative_list, add_negative_list)\r\n",
    "\r\n",
    "            remain_acc = running_corrects.double() / len(remain_negative_list)\r\n",
    "            print('remiam negative size: {}, acc: {:.4f}'.format(len(remain_negative_list), remain_acc))\r\n",
    "\r\n",
    "            train_dataset.set_negative_list(negative_list)\r\n",
    "            tmp_sampler = CustomBatchSampler(train_dataset.get_positive_num(), train_dataset.get_negative_num(),\r\n",
    "                                             batch_positive, batch_negative)\r\n",
    "            data_loaders['train'] = DataLoader(train_dataset, batch_size=batch_total, sampler=tmp_sampler,\r\n",
    "                                               num_workers=8, drop_last=True)\r\n",
    "            data_loaders['add_negative'] = add_negative_list\r\n",
    "\r\n",
    "            data_sizes['train'] = len(tmp_sampler)\r\n",
    "\r\n",
    "        save_model(model, 'models/linear_svm_alexnet_car_%d.pth' % epoch)\r\n",
    "\r\n",
    "    time_elapsed = time.time() - since\r\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
    "        time_elapsed // 60, time_elapsed % 60))\r\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
    "\r\n",
    "    # load best model weights\r\n",
    "    model.load_state_dict(best_model_weights)\r\n",
    "    return model\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "    data_loaders, data_sizes = load_data('./data/classifier_car')\r\n",
    "\r\n",
    "    model_path = './models/alexnet_car.pth'\r\n",
    "    model = alexnet()\r\n",
    "    num_classes = 2\r\n",
    "    num_features = model.classifier[6].in_features\r\n",
    "    model.classifier[6] = nn.Linear(num_features, num_classes)\r\n",
    "    model.load_state_dict(torch.load(model_path))\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    for param in model.parameters():\r\n",
    "        param.requires_grad = False\r\n",
    "\r\n",
    "    model.classifier[6] = nn.Linear(num_features, num_classes)\r\n",
    "\r\n",
    "    model = model.to(device)\r\n",
    "\r\n",
    "    criterion = hinge_loss\r\n",
    "\r\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\r\n",
    "\r\n",
    "    lr_schduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\r\n",
    "\r\n",
    "    best_model = train_model(data_loaders, model, criterion, optimizer, lr_schduler, num_epochs=10, device=device)\r\n",
    "\r\n",
    "    save_model(best_model, 'models/best_linear_svm_alexnet_car.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bounding Box Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data(data_root_dir):\r\n",
    "    transform = transforms.Compose([\r\n",
    "        transforms.ToPILImage(),\r\n",
    "        transforms.Resize((227, 227)),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
    "    ])\r\n",
    "\r\n",
    "    data_set = BBoxRegressionDataset(data_root_dir, transform=transform)\r\n",
    "    data_loader = DataLoader(data_set, batch_size=128, shuffle=True, num_workers=8)\r\n",
    "\r\n",
    "    return data_loader\r\n",
    "\r\n",
    "\r\n",
    "def train_model(data_loader, feature_model, model, criterion, optimizer, lr_scheduler, num_epochs=25, device=None):\r\n",
    "    since = time.time()\r\n",
    "\r\n",
    "    model.train()  # Set model to training mode\r\n",
    "    loss_list = list()\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
    "        print('-' * 10)\r\n",
    "\r\n",
    "        running_loss = 0.0\r\n",
    "\r\n",
    "        # Iterate over data.\r\n",
    "        for inputs, targets in data_loader:\r\n",
    "            inputs = inputs.to(device)\r\n",
    "            targets = targets.float().to(device)\r\n",
    "\r\n",
    "            # feature extraction\r\n",
    "            features = feature_model.features(inputs)\r\n",
    "            features = torch.flatten(features, 1)\r\n",
    "\r\n",
    "            # zero the parameter gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "\r\n",
    "            # forward\r\n",
    "            outputs = model(features)\r\n",
    "            loss = criterion(outputs, targets)\r\n",
    "\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "\r\n",
    "            # statistics\r\n",
    "            running_loss += loss.item() * inputs.size(0)\r\n",
    "            lr_scheduler.step()\r\n",
    "\r\n",
    "        epoch_loss = running_loss / data_loader.dataset.__len__()\r\n",
    "        loss_list.append(epoch_loss)\r\n",
    "\r\n",
    "        print('{} Loss: {:.4f}'.format(epoch, epoch_loss))\r\n",
    "\r\n",
    "        util.save_model(model, './models/bbox_regression_%d.pth' % epoch)\r\n",
    "\r\n",
    "    print()\r\n",
    "\r\n",
    "    time_elapsed = time.time() - since\r\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
    "\r\n",
    "    return loss_list\r\n",
    "\r\n",
    "\r\n",
    "def get_model(device=None):\r\n",
    "\r\n",
    "    model = alexNet(num_classes=2)\r\n",
    "    model.load_state_dict(torch.load('./models/best_linear_svm_alexnet_car.pth'))\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    for param in model.parameters():\r\n",
    "        param.requires_grad = False\r\n",
    "    if device:\r\n",
    "        model = model.to(device)\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    data_loader = load_data('./data/bbox_regression')\r\n",
    "\r\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    # feature extraction\r\n",
    "    feature_model = get_model(device)\r\n",
    "\r\n",
    "    in_features = 256 * 6 * 6\r\n",
    "    out_features = 4\r\n",
    "    # Bounding Box Coordinate Prediction\r\n",
    "    model = nn.Linear(in_features, out_features)\r\n",
    "    model.to(device)\r\n",
    "\r\n",
    "    criterion = nn.MSELoss()\r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\r\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\r\n",
    "\r\n",
    "    loss_list = train_model(data_loader, feature_model, model, criterion, optimizer, lr_scheduler, device=device,\r\n",
    "                            num_epochs=12)\r\n",
    "    util.plot_loss(loss_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_device():\r\n",
    "    return torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "\r\n",
    "def get_transform():\r\n",
    "    transform = transforms.Compose([\r\n",
    "        transforms.ToPILImage(),\r\n",
    "        transforms.Resize((227, 227)),\r\n",
    "        transforms.RandomHorizontalFlip(),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
    "    ])\r\n",
    "    return transform\r\n",
    "\r\n",
    "\r\n",
    "def get_model(device=None):\r\n",
    "    model = alexnet()\r\n",
    "    num_classes = 2\r\n",
    "    num_features = model.classifier[6].in_features\r\n",
    "    model.classifier[6] = nn.Linear(num_features, num_classes)\r\n",
    "    model.load_state_dict(torch.load('./models/best_linear_svm_alexnet_car.pth'))\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    for param in model.parameters():\r\n",
    "        param.requires_grad = False\r\n",
    "    if device:\r\n",
    "        model = model.to(device)\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def draw_box_with_text(img, rect_list, score_list):\r\n",
    "    for i in range(len(rect_list)):\r\n",
    "        xmin, ymin, xmax, ymax = rect_list[i]\r\n",
    "        score = score_list[i]\r\n",
    "\r\n",
    "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color=(0, 0, 255), thickness=1)\r\n",
    "        cv2.putText(img, \"{:.3f}\".format(score), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\r\n",
    "\r\n",
    "\r\n",
    "def nms(rect_list, score_list):\r\n",
    "    nms_rects = list()\r\n",
    "    nms_scores = list()\r\n",
    "\r\n",
    "    rect_array = np.array(rect_list)\r\n",
    "    score_array = np.array(score_list)\r\n",
    "\r\n",
    "    idxs = np.argsort(score_array)[::-1]\r\n",
    "    rect_array = rect_array[idxs]\r\n",
    "    score_array = score_array[idxs]\r\n",
    "\r\n",
    "    thresh = 0.3\r\n",
    "    while len(score_array) > 0:\r\n",
    "        nms_rects.append(rect_array[0])\r\n",
    "        nms_scores.append(score_array[0])\r\n",
    "        rect_array = rect_array[1:]\r\n",
    "        score_array = score_array[1:]\r\n",
    "\r\n",
    "        length = len(score_array)\r\n",
    "        if length <= 0:\r\n",
    "            break\r\n",
    "\r\n",
    "        iou_scores = util.iou(np.array(nms_rects[len(nms_rects) - 1]), rect_array)\r\n",
    "        idxs = np.where(iou_scores < thresh)[0]\r\n",
    "        rect_array = rect_array[idxs]\r\n",
    "        score_array = score_array[idxs]\r\n",
    "\r\n",
    "    return nms_rects, nms_scores\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    device = get_device()\r\n",
    "    transform = get_transform()\r\n",
    "    model = get_model(device=device) # best_linear_svm_alexnet_car\r\n",
    "\r\n",
    "    gs = selectivesearch.get_selective_search()\r\n",
    "\r\n",
    "    test_img_path = '../imgs/000012.jpg'\r\n",
    "    test_xml_path = '../imgs/000012.xml'\r\n",
    "\r\n",
    "    img = cv2.imread(test_img_path)\r\n",
    "    dst = copy.deepcopy(img)\r\n",
    "\r\n",
    "    bndboxs = util.parse_xml(test_xml_path)\r\n",
    "    for bndbox in bndboxs:\r\n",
    "        xmin, ymin, xmax, ymax = bndbox\r\n",
    "        cv2.rectangle(dst, (xmin, ymin), (xmax, ymax), color=(0, 255, 0), thickness=1)\r\n",
    "\r\n",
    "    selectivesearch.config(gs, img, strategy='f')\r\n",
    "    rects = selectivesearch.get_rects(gs)\r\n",
    "\r\n",
    "    svm_thresh = 0.60\r\n",
    "\r\n",
    "    score_list = list()\r\n",
    "    positive_list = list()\r\n",
    "\r\n",
    "    start = time.time()\r\n",
    "    for rect in rects:\r\n",
    "        xmin, ymin, xmax, ymax = rect\r\n",
    "        rect_img = img[ymin:ymax, xmin:xmax]\r\n",
    "\r\n",
    "        rect_transform = transform(rect_img).to(device)\r\n",
    "        output = model(rect_transform.unsqueeze(0))[0]\r\n",
    "\r\n",
    "        if torch.argmax(output).item() == 1:\r\n",
    "            probs = torch.softmax(output, dim=0).cpu().numpy()\r\n",
    "\r\n",
    "            if probs[1] >= svm_thresh:\r\n",
    "                score_list.append(probs[1])\r\n",
    "                positive_list.append(rect)\r\n",
    "                print(rect, output, probs)\r\n",
    "\r\n",
    "    end = time.time()\r\n",
    "    print('detect time: %d s' % (end - start))\r\n",
    "\r\n",
    "    # Non Maximum Suppression\r\n",
    "    nms_rects, nms_scores = nms(positive_list, score_list)\r\n",
    "    print(nms_rects)\r\n",
    "    print(nms_scores)\r\n",
    "    draw_box_with_text(dst, nms_rects, nms_scores)\r\n",
    "\r\n",
    "    cv2.imshow('img', dst)\r\n",
    "    cv2.waitKey(0)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c18c2ce2eeff7956326c52dfc6c88194418eebb74e6de9b69ae4a4f626458f80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}