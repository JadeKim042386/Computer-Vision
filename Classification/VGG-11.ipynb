{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VGG-11 Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class VGG11(nn.Module):\r\n",
    "  def __init__(self, num_classes=10):\r\n",
    "    super(VGG11, self).__init__()\r\n",
    "\r\n",
    "    self.relu = nn.ReLU(inplace=True)\r\n",
    "    \r\n",
    "    # Convolution Feature Extraction Part\r\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\r\n",
    "    self.bn1   = nn.BatchNorm2d(64)\r\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 112 x 112\r\n",
    "\r\n",
    "    # Fill empty parts with proper code\r\n",
    "    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\r\n",
    "    self.bn2   = nn.BatchNorm2d(128)\r\n",
    "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 56 x 56\r\n",
    "\r\n",
    "    self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\r\n",
    "    self.bn3_1   = nn.BatchNorm2d(256)\r\n",
    "    self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\r\n",
    "    self.bn3_2   = nn.BatchNorm2d(256)\r\n",
    "    self.pool3   = nn.MaxPool2d(kernel_size=2, stride=2) # 28 x 28\r\n",
    "\r\n",
    "    self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\r\n",
    "    self.bn4_1   = nn.BatchNorm2d(512)\r\n",
    "    self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\r\n",
    "    self.bn4_2   = nn.BatchNorm2d(512)\r\n",
    "    self.pool4   = nn.MaxPool2d(kernel_size=2, stride=2) # 14 x 14\r\n",
    "\r\n",
    "    self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\r\n",
    "    self.bn5_1   = nn.BatchNorm2d(512)\r\n",
    "    self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\r\n",
    "    self.bn5_2   = nn.BatchNorm2d(512)\r\n",
    "    self.pool5   = nn.MaxPool2d(kernel_size=2, stride=2) # 7 x 7\r\n",
    "\r\n",
    "    # Fully Connected Classifier Part\r\n",
    "    self.fc1      = nn.Linear(512*7*7, 4096, bias=True) # 7 x 7 x 512\r\n",
    "    self.dropout1 = nn.Dropout()\r\n",
    "    self.fc2      = nn.Linear(4096, 4096, bias=True)\r\n",
    "    self.dropout2 = nn.Dropout()\r\n",
    "    \r\n",
    "    self.fc3      = nn.Linear(4096, num_classes, bias=True)\r\n",
    "\r\n",
    "  def forward(self, x):\r\n",
    "    # Convolution Feature Extraction Part\r\n",
    "    x = self.conv1(x)\r\n",
    "    x = self.bn1(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.pool1(x)\r\n",
    "\r\n",
    "    x = self.conv2(x)\r\n",
    "    x = self.bn2(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.pool2(x)\r\n",
    "\r\n",
    "    x = self.conv3_1(x)\r\n",
    "    x = self.bn3_1(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.conv3_2(x)\r\n",
    "    x = self.bn3_2(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.pool3(x)\r\n",
    "\r\n",
    "    x = self.conv4_1(x)\r\n",
    "    x = self.bn4_1(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.conv4_2(x)\r\n",
    "    x = self.bn4_2(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.pool4(x)\r\n",
    "\r\n",
    "    x = self.conv5_1(x)\r\n",
    "    x = self.bn5_1(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.conv5_2(x)\r\n",
    "    x = self.bn5_2(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.pool5(x)\r\n",
    "\r\n",
    "    x = torch.flatten(x, 1)\r\n",
    "    x = self.fc1(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.dropout1(x)\r\n",
    "    \r\n",
    "    x = self.fc2(x)\r\n",
    "    x = self.relu(x)\r\n",
    "    x = self.dropout2(x)\r\n",
    "    \r\n",
    "    x = self.fc3(x)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## pre-trained VGG-11"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchvision.models import vgg11\r\n",
    "\r\n",
    "pretrained = True \r\n",
    "model_finetune = vgg11(pretrained).cuda()\r\n",
    "\r\n",
    "model_finetune.classifier[6] = nn.Linear(4096, 10, bias=True).cuda()\r\n",
    "\r\n",
    "for param in model_finetune.features:\r\n",
    "    if isinstance(param, nn.Conv2d):\r\n",
    "        param.weight.requires_grad = False"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c18c2ce2eeff7956326c52dfc6c88194418eebb74e6de9b69ae4a4f626458f80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}