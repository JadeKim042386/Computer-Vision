{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "설명 : https://herbwood.tistory.com/8?category=856250  \r\n",
    "코드 : https://github.com/gary1346aa/Fast-RCNN-Object-Detection-Pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RoI(Region of Interest) pooling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 마지막 max pooling layer를 RoI pooling layer로 대체하여 고정된 크기의 feature map을 다음 fc layer에 전달  \r\n",
    "- region of interest의 좌표는 원본 이미지 크기에서 region of interest가 차지하는 비율 형식으로 저장되어 있다. 따라서 rois에 저장된 값들은 0~1 사이의 값을 가진다. 이를 feature map(=14x14)의 크기에 맞게 feature map의 width, height를 곱해주고, numpy에서 제공하는 floor(내림), ceil(올림) 함수를 활용하여 feature map 내 region proposal이 encode하는 영역을 찾는다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SlowROIPool(nn.Module):    \r\n",
    "    def __init__(self, output_size):\r\n",
    "        super().__init__()\r\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(output_size)\r\n",
    "        self.size = output_size\r\n",
    "    \r\n",
    "    # images : 원본 이미지\r\n",
    "    # rois : region of interests\r\n",
    "    # roi_idx : region of interest의 index 리스트\r\n",
    "    def forward(self, images, rois, roi_idx):\r\n",
    "        n = rois.shape[0] # region of interest의 수\r\n",
    "        \r\n",
    "        # 고정된 크기로 들어오기 때문에 전부 다 14x14\r\n",
    "        h = images.size(2) # h : feature map height\r\n",
    "        w = images.size(3) # w : feature map width\r\n",
    "        \r\n",
    "        # region of interst의 (x1, y1, x2, y2)의 행렬\r\n",
    "        # 상대 좌표로 들어옴\r\n",
    "        x1 = rois[:,0]\r\n",
    "        y1 = rois[:,1]\r\n",
    "        x2 = rois[:,2]\r\n",
    "        y2 = rois[:,3]\r\n",
    "        \r\n",
    "        # region of interest의 상대좌표를 feature map에 맞게 절대좌표로 변환함\r\n",
    "        x1 = np.floor(x1 * w).astype(int)\r\n",
    "        x2 = np.ceil(x2 * w).astype(int)\r\n",
    "        y1 = np.floor(y1 * h).astype(int)\r\n",
    "        y2 = np.ceil(y2 * h).astype(int)\r\n",
    "\r\n",
    "        res = []\r\n",
    "        # region of interest의 수만큼 순회\r\n",
    "        for i in range(n):\r\n",
    "            img = images[roi_idx[i]].unsqueeze(0) # roi_idx i번째 해당하는 feature map\r\n",
    "            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]] # 잘라내기\r\n",
    "            img = self.maxpool(img) # adaptive average pooling\r\n",
    "            res.append(img)\r\n",
    "        res = torch.cat(res, dim=0)\r\n",
    "        return res # 7x7x(# of region proposals)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initializing pre-trained network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class RCNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        rawnet = torchvision.models.vgg16_bn(pretrained=True)  # pre-trained된 vgg16_bn 모델 가져오기 \r\n",
    "        self.seq = nn.Sequential(*list(rawnet.features.children())[:-1]) # 마지막 max pooling 제거\r\n",
    "        self.roipool = SlowROIPool(output_size=(7, 7)) # 마지막 pooling layer, roi pooling으로 대체\r\n",
    "        self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1])  # 마지막 fc layer 제거\r\n",
    "\r\n",
    "        _x = Variable(torch.Tensor(1, 3, 224, 224))\r\n",
    "        _r = np.array([[0., 0., 1., 1.]])\r\n",
    "        _ri = np.array([0])\r\n",
    "        _x = self.feature(self.roipool(self.seq(_x), _r, _ri).view(1, -1)) # 7x7x(# of region proposals)\r\n",
    "        \r\n",
    "        feature_dim = _x.size(1) \r\n",
    "        self.cls_score = nn.Linear(feature_dim, N_CLASS+1) # classifier\r\n",
    "        self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1)) # bounding box regressor\r\n",
    "        \r\n",
    "        self.cel = nn.CrossEntropyLoss()\r\n",
    "        self.sl1 = nn.SmoothL1Loss()\r\n",
    "\r\n",
    "    def forward(self, inp, rois, ridx):\r\n",
    "        res = inp # images\r\n",
    "        res = self.seq(res) # ~pre-pooling\r\n",
    "        res = self.roipool(res, rois, ridx) # roi pooling\r\n",
    "        res = res.detach() # 연산 x\r\n",
    "        res = res.view(res.size(0), -1)\r\n",
    "        feat = self.feature(res) # fc layers\r\n",
    "\r\n",
    "        cls_score = self.cls_score(feat) # classification result\r\n",
    "        bbox = self.bbox(feat).view(-1, N_CLASS+1, 4) # bounding box regressor result\r\n",
    "        \r\n",
    "        return cls_score, bbox\r\n",
    "\r\n",
    "    def calc_loss(self, probs, bbox, labels, gt_bbox):\r\n",
    "        loss_sc = self.cel(probs, labels) # crossentropy loss\r\n",
    "        \r\n",
    "        lbl = labels.view(-1, 1, 1).expand(labels.size(0), 1, 4)\r\n",
    "        mask = (labels != 0).float().view(-1, 1).expand(labels.size(0), 4)\r\n",
    "        loss_loc = self.sl1(bbox.gather(1, lbl).squeeze(1) * mask, gt_bbox * mask) # 예측한 bounding box 좌표와 실제 bounding box의 좌표의 Smooth L1 loss\r\n",
    "        \r\n",
    "        # multi-task loss, crossentropy loss, smooth l1 loss\r\n",
    "        lmb = 1.0\r\n",
    "        loss = loss_sc + lmb * loss_loc\r\n",
    "        \r\n",
    "        return loss, loss_sc, loss_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Fast R-CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val=False):\r\n",
    "    sc, r_bbox = rcnn(img, rois, ridx) # class score, bbox\r\n",
    "    loss, loss_sc, loss_loc = rcnn.calc_loss(sc, r_bbox, gt_cls, gt_tbbox) # losses(Multi-task loss, Crossentropy loss, Smooth L1 Loss)\r\n",
    "    fl = loss.data.cpu().numpy()[0]\r\n",
    "    fl_sc = loss_sc.data.cpu().numpy()[0]\r\n",
    "    fl_loc = loss_loc.data.cpu().numpy()[0]\r\n",
    "\r\n",
    "    if not is_val:\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "    return fl, fl_sc, fl_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 학습 시 feature sharing을 가능하게 하는 Hierarchical sampling 방법을 사용\r\n",
    "def train_epoch(run_set, is_val=False):\r\n",
    "    I = 2   # number of image : 2\r\n",
    "    B = 64  # number of rois per image : 64\r\n",
    "    POS = int(B * 0.25)  # positive samples : 16\r\n",
    "    NEG = B - POS # negative samples : 48\r\n",
    "    \r\n",
    "    # shffle images\r\n",
    "    Nimg = len(run_set)\r\n",
    "    perm = np.random.permutation(Nimg)\r\n",
    "    perm = run_set[perm]\r\n",
    "    \r\n",
    "    losses = []\r\n",
    "    losses_sc = []\r\n",
    "    losses_loc = []\r\n",
    "    \r\n",
    "    # 전체 이미지를 I(=2)개씩만큼 처리\r\n",
    "    for i in trange(0, Nimg, I):\r\n",
    "        lb = i\r\n",
    "        rb = min(i+I, Nimg)\r\n",
    "        torch_seg = torch.from_numpy(perm[lb:rb]) # read 2 images\r\n",
    "        img = Variable(train_imgs[torch_seg], volatile=is_val).cuda()\r\n",
    "        ridx = []\r\n",
    "        glo_ids = []\r\n",
    "\r\n",
    "        for j in range(lb, rb):\r\n",
    "            info = train_img_info[perm[j]]\r\n",
    "            \r\n",
    "            # roi의 positive, negative idx에 대한 리스트\r\n",
    "            pos_idx = info['pos_idx']\r\n",
    "            neg_idx = info['neg_idx']\r\n",
    "            ids = []\r\n",
    "\r\n",
    "            if len(pos_idx) > 0:\r\n",
    "                ids.append(np.random.choice(pos_idx, size=POS))\r\n",
    "            if len(neg_idx) > 0:\r\n",
    "                ids.append(np.random.choice(neg_idx, size=NEG))\r\n",
    "            if len(ids) == 0:\r\n",
    "                continue\r\n",
    "            ids = np.concatenate(ids, axis=0)\r\n",
    "            \r\n",
    "            # glo_ids : 두 이미지에 대한 positive, negative sample의 idx를 저장한 리스트\r\n",
    "            glo_ids.append(ids)\r\n",
    "            ridx += [j-lb] * ids.shape[0]\r\n",
    "\r\n",
    "        if len(ridx) == 0:\r\n",
    "            continue\r\n",
    "        glo_ids = np.concatenate(glo_ids, axis=0)\r\n",
    "        ridx = np.array(ridx)\r\n",
    "        rois = train_roi[glo_ids]\r\n",
    "        gt_cls = Variable(torch.from_numpy(train_cls[glo_ids]), volatile=is_val).cuda()\r\n",
    "        gt_tbbox = Variable(torch.from_numpy(train_tbbox[glo_ids]), volatile=is_val).cuda()\r\n",
    "\r\n",
    "        loss, loss_sc, loss_loc = train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val=is_val)\r\n",
    "        losses.append(loss)\r\n",
    "        losses_sc.append(loss_sc)\r\n",
    "        losses_loc.append(loss_loc)\r\n",
    "\r\n",
    "    avg_loss = np.mean(losses)\r\n",
    "    avg_loss_sc = np.mean(losses_sc)\r\n",
    "    avg_loss_loc = np.mean(losses_loc)\r\n",
    "    print(f'Avg loss = {avg_loss:.4f}; loss_sc = {avg_loss_sc:.4f}, loss_loc = {avg_loss_loc:.4f}')\r\n",
    "    \r\n",
    "    return losses, losses_sc, losses_loc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bounding Box Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def reg_to_bbox(img_size, reg, box):\r\n",
    "    img_width, img_height = img_size\r\n",
    "    bbox_width = box[:,2] - box[:,0] + 1.0\r\n",
    "    bbox_height = box[:,3] - box[:,1] + 1.0\r\n",
    "    bbox_ctr_x = box[:,0] + 0.5 * bbox_width\r\n",
    "    bbox_ctr_y = box[:,1] + 0.5 * bbox_height\r\n",
    "\r\n",
    "    bbox_width = bbox_width[:,np.newaxis]\r\n",
    "    bbox_height = bbox_height[:,np.newaxis]\r\n",
    "    bbox_ctr_x = bbox_ctr_x[:,np.newaxis]\r\n",
    "    bbox_ctr_y = bbox_ctr_y[:,np.newaxis]\r\n",
    "\r\n",
    "    out_ctr_x = reg[:,:,0] * bbox_width + bbox_ctr_x\r\n",
    "    out_ctr_y = reg[:,:,1] * bbox_height + bbox_ctr_y\r\n",
    "\r\n",
    "    out_width = bbox_width * np.exp(reg[:,:,2])\r\n",
    "    out_height = bbox_height * np.exp(reg[:,:,3])\r\n",
    "\r\n",
    "    return np.array([\r\n",
    "        np.maximum(0, out_ctr_x - 0.5 * out_width),\r\n",
    "        np.maximum(0, out_ctr_y - 0.5 * out_height),\r\n",
    "        np.minimum(img_width, out_ctr_x + 0.5 * out_width),\r\n",
    "        np.minimum(img_height, out_ctr_y + 0.5 * out_height)\r\n",
    "    ]).transpose([1, 2, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## non_maximum_suppression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def calc_ious(ex_rois, gt_rois):\r\n",
    "    ex_area = (1. + ex_rois[:,2] - ex_rois[:,0]) * (1. + ex_rois[:,3] - ex_rois[:,1])\r\n",
    "    gt_area = (1. + gt_rois[:,2] - gt_rois[:,0]) * (1. + gt_rois[:,3] - gt_rois[:,1])\r\n",
    "    area_sum = ex_area.reshape((-1, 1)) + gt_area.reshape((1, -1))\r\n",
    "\r\n",
    "    lb = np.maximum(ex_rois[:,0].reshape((-1, 1)), gt_rois[:,0].reshape((1, -1)))\r\n",
    "    rb = np.minimum(ex_rois[:,2].reshape((-1, 1)), gt_rois[:,2].reshape((1, -1)))\r\n",
    "    tb = np.maximum(ex_rois[:,1].reshape((-1, 1)), gt_rois[:,1].reshape((1, -1)))\r\n",
    "    ub = np.minimum(ex_rois[:,3].reshape((-1, 1)), gt_rois[:,3].reshape((1, -1)))\r\n",
    "\r\n",
    "    width = np.maximum(1. + rb - lb, 0.)\r\n",
    "    height = np.maximum(1. + ub - tb, 0.)\r\n",
    "    area_i = width * height\r\n",
    "    area_u = area_sum - area_i\r\n",
    "    ious = area_i / area_u\r\n",
    "    return ious"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def non_maximum_suppression(sc, bboxs, iou_threshold=0.7, score_threshold=0.6):\r\n",
    "    nroi = sc.shape[0]\r\n",
    "    idx = np.argsort(sc)[::-1]\r\n",
    "    rb = 0\r\n",
    "    while rb < nroi and sc[idx[rb]] >= score_threshold:\r\n",
    "        rb += 1\r\n",
    "    if rb == 0:\r\n",
    "        return []\r\n",
    "    idx = idx[:rb]\r\n",
    "    sc = sc[idx]\r\n",
    "    bboxs = bboxs[idx,:]\r\n",
    "    ious = calc_ious(bboxs, bboxs)\r\n",
    "\r\n",
    "    res = []\r\n",
    "    for i in range(rb):\r\n",
    "        if i == 0 or ious[i, :i].max() < iou_threshold:\r\n",
    "            res.append(bboxs[i])\r\n",
    "\r\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c18c2ce2eeff7956326c52dfc6c88194418eebb74e6de9b69ae4a4f626458f80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}