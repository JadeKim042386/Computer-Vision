{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![u-net-architecture](../images/u-net-architecture.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overall U-Net"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://github.com/milesial/Pytorch-UNet/tree/master/unet\r\n",
    "class UNet(nn.Module):\r\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\r\n",
    "        super(UNet, self).__init__()\r\n",
    "        self.n_channels = n_channels\r\n",
    "        self.n_classes = n_classes\r\n",
    "        self.bilinear = bilinear\r\n",
    "\r\n",
    "        self.inc = DoubleConv(n_channels, 64) # conv2d -> BN -> ReLU -> conv2d -> BN -> ReLU\r\n",
    "        self.down1 = Down(64, 128) # MaxPool -> DoubleConv\r\n",
    "        self.down2 = Down(128, 256) # MaxPool -> DoubleConv\r\n",
    "        self.down3 = Down(256, 512) # MaxPool -> DoubleConv\r\n",
    "        factor = 2 if bilinear else 1\r\n",
    "        self.down4 = Down(512, 1024 // factor)\r\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\r\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\r\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\r\n",
    "        self.up4 = Up(128, 64, bilinear)\r\n",
    "        self.outc = OutConv(64, n_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x1 = self.inc(x)\r\n",
    "        x2 = self.down1(x1)\r\n",
    "        x3 = self.down2(x2)\r\n",
    "        x4 = self.down3(x3)\r\n",
    "        x5 = self.down4(x4)\r\n",
    "        x = self.up1(x5, x4)\r\n",
    "        x = self.up2(x, x3)\r\n",
    "        x = self.up3(x, x2)\r\n",
    "        x = self.up4(x, x1)\r\n",
    "        logits = self.outc(x)\r\n",
    "        return logits"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DoubleConv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DoubleConv(nn.Module):\r\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\r\n",
    "        super().__init__()\r\n",
    "        if not mid_channels:\r\n",
    "            mid_channels = out_channels\r\n",
    "        self.double_conv = nn.Sequential(\r\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\r\n",
    "            nn.BatchNorm2d(mid_channels),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\r\n",
    "            nn.BatchNorm2d(out_channels),\r\n",
    "            nn.ReLU(inplace=True)\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.double_conv(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Down"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Down(nn.Module):\r\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super().__init__()\r\n",
    "        self.maxpool_conv = nn.Sequential(\r\n",
    "            nn.MaxPool2d(2),\r\n",
    "            DoubleConv(in_channels, out_channels)\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.maxpool_conv(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Up(nn.Module):\r\n",
    "    \"\"\"Upscaling then double conv\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\r\n",
    "        if bilinear:\r\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\r\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\r\n",
    "        else:\r\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\r\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\r\n",
    "\r\n",
    "    def forward(self, x1, x2):\r\n",
    "        x1 = self.up(x1)\r\n",
    "        # input is CHW\r\n",
    "        diffY = x2.size()[2] - x1.size()[2]\r\n",
    "        diffX = x2.size()[3] - x1.size()[3]\r\n",
    "\r\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2]) # left, right, top, bottom\r\n",
    "\r\n",
    "        x = torch.cat([x2, x1], dim=1)\r\n",
    "        return self.conv(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OutConv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class OutConv(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels):\r\n",
    "        super(OutConv, self).__init__()\r\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return self.conv(x)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "c18c2ce2eeff7956326c52dfc6c88194418eebb74e6de9b69ae4a4f626458f80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}